{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'image-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'capstone_data'\n",
    "s3_dataPath = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "train_location = os.path.join(s3_dataPath, 'train')\n",
    "val_location = os.path.join(s3_dataPath, 'val')\n",
    "test_location = os.path.join(s3_dataPath, 'test')\n",
    "\n",
    "s3_lstPath = 's3://{}/lst_files'.format(bucket)\n",
    "\n",
    "train_lst = os.path.join(s3_lstPath, 'training.lst')\n",
    "val_lst = os.path.join(s3_lstPath, 'validation.lst')\n",
    "test_lst = os.path.join(s3_lstPath, 'testing.lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-991170486756/capstone_data/train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Image Classifier\n",
    "\n",
    "We will be using the HyperParameter Tuning system of AWS, so this process is more complicated than usual. However, it will yield the best results by finding the best model out of a random set of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the AWS Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet = sagemaker.estimator.Estimator(role=role, \n",
    "                                       sagemaker_session=sagemaker_session, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.p2.xlarge',\n",
    "                                       output_path=\"s3://{}/{}/output\".format(bucket, 'ResNet'), \n",
    "                                       image_name=container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamaters\n",
    "\n",
    "You can read the documentation for all the Hyperparameters of the Image Classification Algorithm <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html>here</a>.<br>\n",
    "<ul>\n",
    "    <li><b>(Required) num_classes</b>: This is the number of output classes for the new dataset. Ours will be 2 for normal or pneumonia</li>\n",
    "    <li><b>(Required) num_training_samples</b>: This is the total number of training samples. The training set has 5,216 images in total.</li>\n",
    "    <li><b>num_layers</b>: The number of layers (depth) for the network. We use will 152 layers</li>\n",
    "    <li><b>image_shape</b>: The input image dimensions,'num_channels, height, width', for the network. It should be no larger than the actual image size. The number of channels should be same as the actual image.</li>\n",
    "    <li><b>mini_batch_size</b>: The number of training samples used for each mini batch. In distributed training, the number of training samples used per batch will be N * mini_batch_size where N is the number of hosts on which training is run.</li>\n",
    "    <li><b>epochs</b>: Number of training epochs.</li>\n",
    "    <li><b>learning_rate</b>: Learning rate for training.</li>\n",
    "    <li><b>precision_dtype</b>: Training datatype precision (default: float32). If set to 'float16', the training will be done in mixed_precision mode and will be faster than float32 mode</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet.set_hyperparameters(num_layers=152, #152 layers for ResNet-152\n",
    "                           image_shape= \"3,224,224\", #The dimensions of our cleaned images\n",
    "                           mini_batch_size=32, #Each batch will have 64 images\n",
    "                           epochs=10, #10 epochs or training iterations through the training set\n",
    "                           learning_rate = 0.01, #Learning rate used for the optimizer of the model which is sgd\n",
    "                           precision_dtype = 'float32',\n",
    "                           num_training_samples=5215,\n",
    "                           num_classes=2\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "I will tune the model by some of the embedded Image Classifier hyperparameters, you can read more <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/IC-tuning.html>here</a>. The goal would be to select the best model that is chosen by the highest validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner, CategoricalParameter\n",
    "\n",
    "ResNet_hyperparameter_tuner = HyperparameterTuner(estimator=ResNet, \n",
    "                                                  objective_metric_name='validation:accuracy', \n",
    "                                                  objective_type='Maximize', \n",
    "                                                  max_jobs=5, #Going to run 20 different models\n",
    "                                                  max_parallel_jobs=1, #Going to train 3 models at the same time\n",
    "                                                  hyperparameter_ranges={\n",
    "                                                      #'mini_batch_size':IntegerParameter(64, 128),\n",
    "                                                      'learning_rate':ContinuousParameter(0.01, 0.1, scaling_type='Logarithmic'),\n",
    "                                                      'optimizer': CategoricalParameter(['sgd', 'adam', \n",
    "                                                                                              'rmsprop', 'nag'])\n",
    "                                                  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(train_location, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(val_location, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "testing_data = sagemaker.session.s3_input(test_location, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "\n",
    "train_data_lst = sagemaker.session.s3_input(train_lst, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_data_lst = sagemaker.session.s3_input(val_lst, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "test_data_lst = sagemaker.session.s3_input(test_lst, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train':train_data, 'validation': validation_data, \n",
    "                 'train_lst':train_data_lst, 'validation_lst':validation_data_lst}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Hyperparameter Tuning job\n",
    "\n",
    "Here is where AWS will train multiple training jobs to find the best model out of a number of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_hyperparameter_tuner.fit(data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................._s\n"
     ]
    }
   ],
   "source": [
    "ResNet_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training numerous models, I will find the one that provided the best training job. <br><br>\n",
    "Which is here below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image-classification-200112-2133-002-5c8e0b5a'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to create an AWS <a href=https://sagemaker.readthedocs.io/en/stable/estimators.html>Estimator</a> that uses the training job's model artifacts from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-12 23:14:27 Starting - Preparing the instances for training\n",
      "2020-01-12 23:14:27 Downloading - Downloading input data\n",
      "2020-01-12 23:14:27 Training - Training image download completed. Training in progress.\n",
      "2020-01-12 23:14:27 Uploading - Uploading generated training model\n",
      "2020-01-12 23:14:27 Completed - Training job completed\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:25 INFO 139726532032320] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:25 INFO 139726532032320] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.05561869868809854', u'optimizer': u'adam', u'_tuning_objective_metric': u'validation:accuracy', u'precision_dtype': u'float32', u'epochs': u'10', u'num_training_samples': u'5215', u'num_layers': u'152', u'mini_batch_size': u'32', u'image_shape': u'3,224,224', u'num_classes': u'2'}\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:25 INFO 139726532032320] Final configuration: {u'optimizer': u'adam', u'_tuning_objective_metric': u'validation:accuracy', u'learning_rate': u'0.05561869868809854', u'epochs': u'10', u'lr_scheduler_factor': 0.1, u'num_layers': u'152', u'precision_dtype': u'float32', u'mini_batch_size': u'32', u'num_classes': u'2', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': 0, u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,224,224', u'gamma': 0.9, u'num_training_samples': u'5215'}\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:25 INFO 139726532032320] Searching for .lst files in /opt/ml/input/data/train_lst.\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:25 INFO 139726532032320] Creating record files for training.lst\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] Done creating record files...\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] Searching for .lst files in /opt/ml/input/data/validation_lst.\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] Creating record files for validation.lst\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] Done creating record files...\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] use_pretrained_model: 0\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] multi_label: 0\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] Performing random weight initialization\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] num_layers: 152\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] epochs: 10\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] optimizer: adam\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] beta_1: 0.9\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] beta_2: 0.999\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] eps: 1e-08\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] learning_rate: 0.0556186986881\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] num_training_samples: 5215\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] mini_batch_size: 32\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] num_classes: 2\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] kv_store: device\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] tuning_objective_metric: validation:accuracy\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] --------------------\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:28:31 INFO 139726532032320] Setting number of threads: 3\u001b[0m\n",
      "\u001b[34m[22:28:38] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.1888.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:29:19 INFO 139726532032320] Epoch[0] Batch [20]#011Speed: 15.148 samples/sec#011accuracy=0.700893\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:29:51 INFO 139726532032320] Epoch[0] Batch [40]#011Speed: 17.215 samples/sec#011accuracy=0.727896\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:30:24 INFO 139726532032320] Epoch[0] Batch [60]#011Speed: 18.003 samples/sec#011accuracy=0.736168\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:30:56 INFO 139726532032320] Epoch[0] Batch [80]#011Speed: 18.406 samples/sec#011accuracy=0.737654\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:31:29 INFO 139726532032320] Epoch[0] Batch [100]#011Speed: 18.643 samples/sec#011accuracy=0.738861\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:32:01 INFO 139726532032320] Epoch[0] Batch [120]#011Speed: 18.799 samples/sec#011accuracy=0.735795\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:32:34 INFO 139726532032320] Epoch[0] Batch [140]#011Speed: 18.903 samples/sec#011accuracy=0.738918\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:33:07 INFO 139726532032320] Epoch[0] Batch [160]#011Speed: 18.980 samples/sec#011accuracy=0.740295\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:33:08 INFO 139726532032320] Epoch[0] Train-accuracy=0.740934\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:33:08 INFO 139726532032320] Epoch[0] Time cost=271.388\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:33:08 INFO 139726532032320] Epoch[0] Validation-accuracy=nan\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:33:43 INFO 139726532032320] Epoch[1] Batch [20]#011Speed: 18.751 samples/sec#011accuracy=0.763393\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:34:16 INFO 139726532032320] Epoch[1] Batch [40]#011Speed: 19.130 samples/sec#011accuracy=0.798780\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:34:48 INFO 139726532032320] Epoch[1] Batch [60]#011Speed: 19.271 samples/sec#011accuracy=0.815061\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:35:21 INFO 139726532032320] Epoch[1] Batch [80]#011Speed: 19.334 samples/sec#011accuracy=0.823302\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:35:54 INFO 139726532032320] Epoch[1] Batch [100]#011Speed: 19.374 samples/sec#011accuracy=0.827661\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:36:27 INFO 139726532032320] Epoch[1] Batch [120]#011Speed: 19.414 samples/sec#011accuracy=0.836519\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:36:59 INFO 139726532032320] Epoch[1] Batch [140]#011Speed: 19.437 samples/sec#011accuracy=0.842199\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:37:32 INFO 139726532032320] Epoch[1] Batch [160]#011Speed: 19.450 samples/sec#011accuracy=0.850155\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:37:34 INFO 139726532032320] Epoch[1] Train-accuracy=0.850887\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:37:34 INFO 139726532032320] Epoch[1] Time cost=264.871\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:37:35 INFO 139726532032320] Epoch[1] Validation-accuracy=0.500000\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:37:36 INFO 139726532032320] Storing the best model with validation accuracy: 0.500000\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:37:36 INFO 139726532032320] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:38:10 INFO 139726532032320] Epoch[2] Batch [20]#011Speed: 18.803 samples/sec#011accuracy=0.900298\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:38:43 INFO 139726532032320] Epoch[2] Batch [40]#011Speed: 19.155 samples/sec#011accuracy=0.912348\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:39:16 INFO 139726532032320] Epoch[2] Batch [60]#011Speed: 19.284 samples/sec#011accuracy=0.915984\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:39:48 INFO 139726532032320] Epoch[2] Batch [80]#011Speed: 19.352 samples/sec#011accuracy=0.914352\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:40:21 INFO 139726532032320] Epoch[2] Batch [100]#011Speed: 19.395 samples/sec#011accuracy=0.918007\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:40:54 INFO 139726532032320] Epoch[2] Batch [120]#011Speed: 19.423 samples/sec#011accuracy=0.919680\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:41:26 INFO 139726532032320] Epoch[2] Batch [140]#011Speed: 19.442 samples/sec#011accuracy=0.920213\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:41:59 INFO 139726532032320] Epoch[2] Batch [160]#011Speed: 19.455 samples/sec#011accuracy=0.922943\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:42:01 INFO 139726532032320] Epoch[2] Train-accuracy=0.923225\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:42:01 INFO 139726532032320] Epoch[2] Time cost=264.813\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:42:01 INFO 139726532032320] Epoch[2] Validation-accuracy=nan\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:42:36 INFO 139726532032320] Epoch[3] Batch [20]#011Speed: 18.662 samples/sec#011accuracy=0.936012\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:43:08 INFO 139726532032320] Epoch[3] Batch [40]#011Speed: 19.102 samples/sec#011accuracy=0.952744\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:43:41 INFO 139726532032320] Epoch[3] Batch [60]#011Speed: 19.237 samples/sec#011accuracy=0.946721\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:44:14 INFO 139726532032320] Epoch[3] Batch [80]#011Speed: 19.315 samples/sec#011accuracy=0.944444\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:44:47 INFO 139726532032320] Epoch[3] Batch [100]#011Speed: 19.362 samples/sec#011accuracy=0.946163\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:45:19 INFO 139726532032320] Epoch[3] Batch [120]#011Speed: 19.396 samples/sec#011accuracy=0.945506\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:45:52 INFO 139726532032320] Epoch[3] Batch [140]#011Speed: 19.420 samples/sec#011accuracy=0.945922\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:46:25 INFO 139726532032320] Epoch[3] Batch [160]#011Speed: 19.440 samples/sec#011accuracy=0.946040\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:46:26 INFO 139726532032320] Epoch[3] Train-accuracy=0.945988\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:46:26 INFO 139726532032320] Epoch[3] Time cost=265.016\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:46:28 INFO 139726532032320] Epoch[3] Validation-accuracy=0.687500\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:46:28 INFO 139726532032320] Storing the best model with validation accuracy: 0.687500\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:46:29 INFO 139726532032320] Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:47:03 INFO 139726532032320] Epoch[4] Batch [20]#011Speed: 18.771 samples/sec#011accuracy=0.958333\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:47:36 INFO 139726532032320] Epoch[4] Batch [40]#011Speed: 19.140 samples/sec#011accuracy=0.946646\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:48:08 INFO 139726532032320] Epoch[4] Batch [60]#011Speed: 19.274 samples/sec#011accuracy=0.945184\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:48:41 INFO 139726532032320] Epoch[4] Batch [80]#011Speed: 19.343 samples/sec#011accuracy=0.943673\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:49:14 INFO 139726532032320] Epoch[4] Batch [100]#011Speed: 19.379 samples/sec#011accuracy=0.943069\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:49:47 INFO 139726532032320] Epoch[4] Batch [120]#011Speed: 19.407 samples/sec#011accuracy=0.943440\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:50:19 INFO 139726532032320] Epoch[4] Batch [140]#011Speed: 19.431 samples/sec#011accuracy=0.943484\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:50:52 INFO 139726532032320] Epoch[4] Batch [160]#011Speed: 19.450 samples/sec#011accuracy=0.942741\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:50:54 INFO 139726532032320] Epoch[4] Train-accuracy=0.942515\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:50:54 INFO 139726532032320] Epoch[4] Time cost=264.883\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:50:54 INFO 139726532032320] Epoch[4] Validation-accuracy=nan\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:51:29 INFO 139726532032320] Epoch[5] Batch [20]#011Speed: 18.713 samples/sec#011accuracy=0.949405\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:52:01 INFO 139726532032320] Epoch[5] Batch [40]#011Speed: 19.127 samples/sec#011accuracy=0.961128\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:52:34 INFO 139726532032320] Epoch[5] Batch [60]#011Speed: 19.267 samples/sec#011accuracy=0.957992\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:53:07 INFO 139726532032320] Epoch[5] Batch [80]#011Speed: 19.343 samples/sec#011accuracy=0.957948\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:53:39 INFO 139726532032320] Epoch[5] Batch [100]#011Speed: 19.387 samples/sec#011accuracy=0.948948\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:54:12 INFO 139726532032320] Epoch[5] Batch [120]#011Speed: 19.413 samples/sec#011accuracy=0.945764\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:54:45 INFO 139726532032320] Epoch[5] Batch [140]#011Speed: 19.432 samples/sec#011accuracy=0.946365\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:55:18 INFO 139726532032320] Epoch[5] Batch [160]#011Speed: 19.450 samples/sec#011accuracy=0.947399\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:55:19 INFO 139726532032320] Epoch[5] Train-accuracy=0.947724\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:55:19 INFO 139726532032320] Epoch[5] Time cost=264.877\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:55:21 INFO 139726532032320] Epoch[5] Validation-accuracy=0.625000\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:55:55 INFO 139726532032320] Epoch[6] Batch [20]#011Speed: 18.794 samples/sec#011accuracy=0.943452\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:56:28 INFO 139726532032320] Epoch[6] Batch [40]#011Speed: 19.166 samples/sec#011accuracy=0.958079\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:57:01 INFO 139726532032320] Epoch[6] Batch [60]#011Speed: 19.281 samples/sec#011accuracy=0.952869\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:57:34 INFO 139726532032320] Epoch[6] Batch [80]#011Speed: 19.349 samples/sec#011accuracy=0.954475\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:58:06 INFO 139726532032320] Epoch[6] Batch [100]#011Speed: 19.384 samples/sec#011accuracy=0.955446\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:58:39 INFO 139726532032320] Epoch[6] Batch [120]#011Speed: 19.418 samples/sec#011accuracy=0.957128\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:59:12 INFO 139726532032320] Epoch[6] Batch [140]#011Speed: 19.437 samples/sec#011accuracy=0.958555\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:59:45 INFO 139726532032320] Epoch[6] Batch [160]#011Speed: 19.455 samples/sec#011accuracy=0.957880\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:59:46 INFO 139726532032320] Epoch[6] Train-accuracy=0.957948\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:59:46 INFO 139726532032320] Epoch[6] Time cost=264.808\u001b[0m\n",
      "\u001b[34m[01/12/2020 22:59:46 INFO 139726532032320] Epoch[6] Validation-accuracy=nan\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:00:21 INFO 139726532032320] Epoch[7] Batch [20]#011Speed: 18.743 samples/sec#011accuracy=0.955357\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:00:54 INFO 139726532032320] Epoch[7] Batch [40]#011Speed: 19.145 samples/sec#011accuracy=0.963415\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:01:26 INFO 139726532032320] Epoch[7] Batch [60]#011Speed: 19.287 samples/sec#011accuracy=0.962602\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:01:59 INFO 139726532032320] Epoch[7] Batch [80]#011Speed: 19.356 samples/sec#011accuracy=0.961420\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:02:32 INFO 139726532032320] Epoch[7] Batch [100]#011Speed: 19.404 samples/sec#011accuracy=0.957611\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:03:04 INFO 139726532032320] Epoch[7] Batch [120]#011Speed: 19.436 samples/sec#011accuracy=0.958161\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:03:37 INFO 139726532032320] Epoch[7] Batch [140]#011Speed: 19.459 samples/sec#011accuracy=0.958777\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:04:10 INFO 139726532032320] Epoch[7] Batch [160]#011Speed: 19.472 samples/sec#011accuracy=0.958657\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/12/2020 23:04:11 INFO 139726532032320] Epoch[7] Train-accuracy=0.958333\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:04:11 INFO 139726532032320] Epoch[7] Time cost=264.585\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:04:13 INFO 139726532032320] Epoch[7] Validation-accuracy=0.625000\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:04:47 INFO 139726532032320] Epoch[8] Batch [20]#011Speed: 18.793 samples/sec#011accuracy=0.950893\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:05:20 INFO 139726532032320] Epoch[8] Batch [40]#011Speed: 19.178 samples/sec#011accuracy=0.959604\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:05:53 INFO 139726532032320] Epoch[8] Batch [60]#011Speed: 19.305 samples/sec#011accuracy=0.961578\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:06:26 INFO 139726532032320] Epoch[8] Batch [80]#011Speed: 19.362 samples/sec#011accuracy=0.962577\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:06:58 INFO 139726532032320] Epoch[8] Batch [100]#011Speed: 19.405 samples/sec#011accuracy=0.958230\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:07:31 INFO 139726532032320] Epoch[8] Batch [120]#011Speed: 19.439 samples/sec#011accuracy=0.955579\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:08:04 INFO 139726532032320] Epoch[8] Batch [140]#011Speed: 19.466 samples/sec#011accuracy=0.957668\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:08:36 INFO 139726532032320] Epoch[8] Batch [160]#011Speed: 19.482 samples/sec#011accuracy=0.956910\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:08:38 INFO 139726532032320] Epoch[8] Train-accuracy=0.956983\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:08:38 INFO 139726532032320] Epoch[8] Time cost=264.442\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:08:38 INFO 139726532032320] Epoch[8] Validation-accuracy=nan\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:09:12 INFO 139726532032320] Epoch[9] Batch [20]#011Speed: 18.743 samples/sec#011accuracy=0.964286\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:09:45 INFO 139726532032320] Epoch[9] Batch [40]#011Speed: 19.158 samples/sec#011accuracy=0.964177\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:10:18 INFO 139726532032320] Epoch[9] Batch [60]#011Speed: 19.306 samples/sec#011accuracy=0.963627\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:10:50 INFO 139726532032320] Epoch[9] Batch [80]#011Speed: 19.377 samples/sec#011accuracy=0.967978\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:11:23 INFO 139726532032320] Epoch[9] Batch [100]#011Speed: 19.421 samples/sec#011accuracy=0.967203\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:11:56 INFO 139726532032320] Epoch[9] Batch [120]#011Speed: 19.451 samples/sec#011accuracy=0.966942\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:12:28 INFO 139726532032320] Epoch[9] Batch [140]#011Speed: 19.472 samples/sec#011accuracy=0.966312\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:13:01 INFO 139726532032320] Epoch[9] Batch [160]#011Speed: 19.491 samples/sec#011accuracy=0.965839\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:13:03 INFO 139726532032320] Epoch[9] Train-accuracy=0.966049\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:13:03 INFO 139726532032320] Epoch[9] Time cost=264.317\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:13:04 INFO 139726532032320] Epoch[9] Validation-accuracy=0.937500\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:13:05 INFO 139726532032320] Storing the best model with validation accuracy: 0.937500\u001b[0m\n",
      "\u001b[34m[01/12/2020 23:13:05 INFO 139726532032320] Saved checkpoint to \"/opt/ml/model/image-classification-0010.params\"\u001b[0m\n",
      "Training seconds: 2860\n",
      "Billable seconds: 2860\n"
     ]
    }
   ],
   "source": [
    "aws_estimator = sagemaker.estimator.Estimator.attach(training_job_name='image-classification-200112-2133-002-5c8e0b5a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the AWS Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "aws_classifier = aws_estimator.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = os.path.join(os.getcwd(), 'clean_data/test/PNEUMONIA/test_PNEUMONIA_100.jpeg')\n",
    "from IPython.display import Image\n",
    "Image(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    \n",
    "aws_classifier.content_type = 'application/x-image'\n",
    "result = json.loads(aws_classifier.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: Pneumonia\n",
      "Probability: 0.9999531507492065\n"
     ]
    }
   ],
   "source": [
    "index = np.argmax(result)\n",
    "\n",
    "classes = ['Normal', 'Pneumonia']\n",
    "print('predicted class:', classes[index])\n",
    "print('Probability:', result[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing AWS Model\n",
    "\n",
    "<b>Remember the classes:</b><br>\n",
    "<ul>\n",
    "    <li>Normal Images is 0</li>\n",
    "    <li>Pneumonia Images is 1</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "data_dir = Path(os.path.join(os.getcwd(), 'chest_xray'))\n",
    "test_NORMAL_dir = data_dir / 'test' / 'NORMAL'\n",
    "test_PNEUMONIA_dir = data_dir / 'test' / 'PNEUMONIA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_NORMAL_images = list(test_NORMAL_dir.glob('*.jpeg'))\n",
    "test_PNEUMONIA_images = list(test_PNEUMONIA_dir.glob('*.jpeg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\n",
      "624\n",
      "\n",
      "True Positives: 379\n",
      "False Positives: 81\n",
      "True Negatives: 153\n",
      "False Negatives: 11\n",
      "\n",
      "Accuracy: 0.8525641025641025\n",
      "Recall: 0.9717948717948718\n",
      "Precision: 0.8239130434782609\n",
      "AUC SCORE: 0.8128205128205128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "aws_classifier.content_type = 'application/x-image'\n",
    "\n",
    "y_preds = []\n",
    "y_actual = []\n",
    "for normal_image in test_NORMAL_images:\n",
    "    with open(normal_image, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "        \n",
    "    result = json.loads(aws_classifier.predict(payload))\n",
    "    \n",
    "    predicted_class = np.argmax(result)#This provides the index that has the greatest number which signifies the predicted class\n",
    "    \n",
    "    y_preds.append(predicted_class)\n",
    "    y_actual.append(0)#The actual class is 0 since 0 signifies that it is a normal image\n",
    "    \n",
    "for pneumonia_image in test_PNEUMONIA_images:\n",
    "    with open(pneumonia_image, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "        \n",
    "    result = json.loads(aws_classifier.predict(payload))\n",
    "    \n",
    "    predicted_class = np.argmax(result)#This provides the index that has the greatest number which signifies the predicted class\n",
    "    \n",
    "    y_preds.append(predicted_class)\n",
    "    y_actual.append(1)#The actual class is 1 since 1 signifies that it is an image with Pneumonia\n",
    "    \n",
    "print(len(y_preds))\n",
    "print(len(y_actual))\n",
    "    \n",
    "y_preds = np.array(y_preds)\n",
    "y_actual = np.array(y_actual)\n",
    "\n",
    "\n",
    "tp = np.logical_and(y_actual, y_preds).sum()\n",
    "fp = np.logical_and(1-y_actual, y_preds).sum()\n",
    "tn = np.logical_and(1-y_actual, 1-y_preds).sum()\n",
    "fn = np.logical_and(y_actual, 1-y_preds).sum()\n",
    "    \n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "    \n",
    "print(\"\\nTrue Positives:\", tp)\n",
    "print('False Positives:', fp)\n",
    "print('True Negatives:', tn)\n",
    "print('False Negatives:', fn)\n",
    "\n",
    "print('\\nAccuracy:', accuracy_score(y_pred=y_preds, y_true=y_actual))\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)\n",
    "print('AUC SCORE:', roc_auc_score(y_true=y_actual, y_score=y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Model <br>\n",
    "\n",
    "True Positives: 379<br>\n",
    "False Positives: 81<br>\n",
    "True Negatives: 153<br>\n",
    "False Negatives: 11<br>\n",
    "\n",
    "AUC Score: 0.8128205128205128 (Pretty good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constucting my Convolutional Neural Network\n",
    "\n",
    "I will use the S3 training and validation locations to fit the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_estimator = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='cnn_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-991170486756/capstone_data/train\n",
      "s3://sagemaker-us-east-2-991170486756/capstone_data/val\n",
      "s3://sagemaker-us-east-2-991170486756/capstone_data/test\n"
     ]
    }
   ],
   "source": [
    "print(train_location)\n",
    "print(val_location)\n",
    "print(test_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 05:47:09 Starting - Starting the training job...\n",
      "2020-01-19 05:47:38 Starting - Launching requested ML instances.........\n",
      "2020-01-19 05:49:00 Starting - Preparing the instances for training............\n",
      "2020-01-19 05:50:41 Downloading - Downloading input data...\n",
      "2020-01-19 05:51:40 Training - Downloading the training image.........\n",
      "2020-01-19 05:52:54 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-19 05:52:55,533 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-19 05:52:55,557 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-19 05:52:55,557 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-19 05:52:55,809 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-19 05:52:55,809 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-19 05:52:55,809 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-19 05:52:55,809 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpdlmt7dv2/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=11731 sha256=cbb50d7895def6a5b5d1621cefeaaee6b05baed741bb10544d128f54192da970\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-buiexwh6/wheels/7e/4b/b1/6e81b10cd48561eb4508961f81f870a83ca85868a75e1c4e19\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-19 05:52:58,040 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-19-05-47-08-800\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-05-47-08-800/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.05}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-05-47-08-800/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-19-05-47-08-800\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-05-47-08-800/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.05\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.05\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.05\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:53:06.017 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:53:06.029 algo-1:44 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:53:06.029 algo-1:44 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:53:06.030 algo-1:44 INFO hook.py:325] Monitoring the collections: losses, scalars\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.610814 #011Validation Loss: 0.760825\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.760825).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.573683 #011Validation Loss: 0.806556\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.571547 #011Validation Loss: 0.818399\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.570547 #011Validation Loss: 0.823722\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.570829 #011Validation Loss: 0.825654\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.570383 #011Validation Loss: 0.823472\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.569838 #011Validation Loss: 0.821075\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.569660 #011Validation Loss: 0.826603\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.570026 #011Validation Loss: 0.827563\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.568875 #011Validation Loss: 0.825767\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.568448 #011Validation Loss: 0.823854\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.567094 #011Validation Loss: 0.821564\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.562058 #011Validation Loss: 0.818687\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.529597 #011Validation Loss: 0.777733\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.394212 #011Validation Loss: 0.587363\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.760825 --> 0.587363).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.218383 #011Validation Loss: 1.293732\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.146122 #011Validation Loss: 0.390238\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.587363 --> 0.390238).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.130540 #011Validation Loss: 0.692870\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.107205 #011Validation Loss: 1.290771\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.103764 #011Validation Loss: 0.227304\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.390238 --> 0.227304).  Saving model ...\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 0.5678418155759573\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 377\u001b[0m\n",
      "\u001b[34mFalse Positives: 96\u001b[0m\n",
      "\u001b[34mTrue Negatives: 138\u001b[0m\n",
      "\u001b[34mFalse Negatives: 13\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.8253205128205128\u001b[0m\n",
      "\u001b[34mRecall: 0.9666666666666667\u001b[0m\n",
      "\u001b[34mPrecision: 0.7970401691331924\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.7782051282051282\u001b[0m\n",
      "\u001b[34m[2020-01-19 06:04:16.350 algo-1:44 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-19 06:04:16,665 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-19 06:04:18 Uploading - Uploading generated training model\n",
      "2020-01-19 06:07:46 Completed - Training job completed\n",
      "Training seconds: 1025\n",
      "Billable seconds: 1025\n"
     ]
    }
   ],
   "source": [
    "my_estimator.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model <br>\n",
    "Epochs: 20\n",
    "Learning Rate: 0.05\n",
    "\n",
    "True Positives: 377\n",
    "False Positives: 96\n",
    "True Negatives: 138\n",
    "False Negatives: 13\n",
    "\n",
    "AUC Score: 0.7782051282051282 (It is okay)\n",
    "\n",
    "I will create two other PyTorch training job, but the learning rate is 0.1 and 0.01\n",
    "\n",
    "## Second and Third Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_estimator2 = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='cnn_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.1})\n",
    "\n",
    "my_estimator3 = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='cnn_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 04:53:25 Starting - Starting the training job...\n",
      "2020-01-19 04:53:26 Starting - Launching requested ML instances...\n",
      "2020-01-19 04:54:22 Starting - Preparing the instances for training.........\n",
      "2020-01-19 04:55:43 Downloading - Downloading input data......\n",
      "2020-01-19 04:56:34 Training - Downloading the training image.........\n",
      "2020-01-19 04:58:13 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-19 04:58:14,839 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-19 04:58:14,866 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-19 04:58:17,899 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-19 04:58:18,178 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-19 04:58:18,178 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-19 04:58:18,178 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-19 04:58:18,178 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpwcv8oe96/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=11732 sha256=a2d72bca3eb3144713a167d27d2d51b5598aa554d02e240a9381550b0c1c60c7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-yrjrc_46/wheels/91/0c/93/cf4c4f3f9eb71b4e393b8e0d6a21d297431e33df0294094a7c\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-19 04:58:20,472 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-19-04-53-25-158\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-04-53-25-158/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-04-53-25-158/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-19-04-53-25-158\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-04-53-25-158/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 04:58:28.994 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-19 04:58:29.008 algo-1:44 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 04:58:29.008 algo-1:44 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-19 04:58:29.008 algo-1:44 INFO hook.py:325] Monitoring the collections: scalars, losses\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.592337 #011Validation Loss: 0.806569\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.806569).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.570251 #011Validation Loss: 0.827701\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.569467 #011Validation Loss: 0.822087\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.568207 #011Validation Loss: 0.825712\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.560378 #011Validation Loss: 0.829276\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.480163 #011Validation Loss: 0.839066\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.271556 #011Validation Loss: 1.274059\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.133623 #011Validation Loss: 0.136929\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.806569 --> 0.136929).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.157539 #011Validation Loss: 1.389025\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.083184 #011Validation Loss: 0.182979\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.068628 #011Validation Loss: 0.446897\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.061377 #011Validation Loss: 0.236212\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.052245 #011Validation Loss: 0.153031\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.044179 #011Validation Loss: 0.113419\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.136929 --> 0.113419).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.048532 #011Validation Loss: 0.075178\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.113419 --> 0.075178).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.038271 #011Validation Loss: 0.062417\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.075178 --> 0.062417).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.040473 #011Validation Loss: 0.021960\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.062417 --> 0.021960).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.033261 #011Validation Loss: 0.475598\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.039438 #011Validation Loss: 0.044819\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.030858 #011Validation Loss: 1.372654\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 1.5567246026323118\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 390\u001b[0m\n",
      "\u001b[34mFalse Positives: 197\u001b[0m\n",
      "\u001b[34mTrue Negatives: 37\u001b[0m\n",
      "\u001b[34mFalse Negatives: 0\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.6842948717948718\u001b[0m\n",
      "\u001b[34mRecall: 1.0\u001b[0m\n",
      "\u001b[34mPrecision: 0.6643952299829642\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.579059829059829\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:10:01.254 algo-1:44 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-19 05:10:01,694 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-19 05:10:06 Uploading - Uploading generated training model\n",
      "2020-01-19 05:13:29 Completed - Training job completed\n",
      "Training seconds: 1066\n",
      "Billable seconds: 1066\n"
     ]
    }
   ],
   "source": [
    "my_estimator2.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 05:20:14 Starting - Starting the training job...\n",
      "2020-01-19 05:20:16 Starting - Launching requested ML instances...\n",
      "2020-01-19 05:21:10 Starting - Preparing the instances for training............\n",
      "2020-01-19 05:22:49 Downloading - Downloading input data......\n",
      "2020-01-19 05:24:12 Training - Downloading the training image.......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-19 05:25:19,065 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-19 05:25:19,090 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-19 05:25:22,120 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-19 05:25:22,405 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-19 05:25:22,405 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-19 05:25:22,405 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-19 05:25:22,405 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp1sjsi6hv/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=11731 sha256=0165eb6b7243b2692effb913ba9093851bd9ef0f2e7b3fd49f938cf2afee2a53\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ibzfa3bb/wheels/1d/93/89/eb4b61efb94c701f856ea1d4c49da82d68eca85824cc387fc9\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-19 05:25:24,876 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-19-05-20-14-595\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-05-20-14-595/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-05-20-14-595/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-19-05-20-14-595\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-05-20-14-595/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.01\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\n",
      "2020-01-19 05:25:17 Training - Training image download completed. Training in progress.\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:25:33.530 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:25:33.543 algo-1:44 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:25:33.543 algo-1:44 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:25:33.543 algo-1:44 INFO hook.py:325] Monitoring the collections: losses, scalars\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.696555 #011Validation Loss: 0.694663\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.694663).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.649136 #011Validation Loss: 0.704530\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.619485 #011Validation Loss: 0.719135\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.600082 #011Validation Loss: 0.735417\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.588932 #011Validation Loss: 0.751219\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.581844 #011Validation Loss: 0.765580\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.577081 #011Validation Loss: 0.778281\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.574020 #011Validation Loss: 0.789162\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.573005 #011Validation Loss: 0.797525\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.571579 #011Validation Loss: 0.804260\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.570626 #011Validation Loss: 0.809671\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.570914 #011Validation Loss: 0.813267\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.570915 #011Validation Loss: 0.815880\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.569084 #011Validation Loss: 0.818310\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.571032 #011Validation Loss: 0.819558\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.569836 #011Validation Loss: 0.821171\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.570106 #011Validation Loss: 0.821673\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.569678 #011Validation Loss: 0.822337\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.568864 #011Validation Loss: 0.822983\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.568937 #011Validation Loss: 0.823356\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 0.6821374818682671\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 390\u001b[0m\n",
      "\u001b[34mFalse Positives: 234\u001b[0m\n",
      "\u001b[34mTrue Negatives: 0\u001b[0m\n",
      "\u001b[34mFalse Negatives: 0\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.625\u001b[0m\n",
      "\u001b[34mRecall: 1.0\u001b[0m\n",
      "\u001b[34mPrecision: 0.625\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.5\u001b[0m\n",
      "\u001b[34m[2020-01-19 05:36:36.419 algo-1:44 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-19 05:36:36,752 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-19 05:36:39 Uploading - Uploading generated training model\n",
      "2020-01-19 05:40:07 Completed - Training job completed\n",
      "Training seconds: 1038\n",
      "Billable seconds: 1038\n"
     ]
    }
   ],
   "source": [
    "my_estimator3.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.1<br>\n",
    "\n",
    "True Positives: 390<br>\n",
    "False Positives: 197<br>\n",
    "True Negatives: 37<br>\n",
    "False Negatives: 0<br>\n",
    "\n",
    "AUC Score: 0.579059829059829 (Not that good)\n",
    "\n",
    "\n",
    "### Third Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.01<br>\n",
    "\n",
    "True Positives: 390<br>\n",
    "False Positives: 234<br>\n",
    "True Negatives: 0<br>\n",
    "False Negatives: 0<br>\n",
    "\n",
    "AUC Score: 0.5 (Very bad because it seems that the learning rate was too small to backpropogate effeciently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_estimator4 = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='cnn_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.045})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 08:01:36 Starting - Starting the training job...\n",
      "2020-01-19 08:01:38 Starting - Launching requested ML instances...\n",
      "2020-01-19 08:02:33 Starting - Preparing the instances for training.........\n",
      "2020-01-19 08:03:59 Downloading - Downloading input data......\n",
      "2020-01-19 08:05:06 Training - Downloading the training image.........\n",
      "2020-01-19 08:06:32 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-19 08:06:33,657 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-19 08:06:33,682 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-19 08:06:36,800 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-19 08:06:37,091 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-19 08:06:37,091 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-19 08:06:37,091 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-19 08:06:37,091 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpzqm7kw_p/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=11731 sha256=51f90c02f2fe129b44dcd0bb7f697d3cf76fa9aa05422c87575903852416f4d0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hfl2qffy/wheels/7d/fe/40/0e4f762eb547a4fddbddeac96465b547e091857b8d0a686c8e\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-19 08:06:39,488 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.045\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-19-08-01-36-460\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-08-01-36-460/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.045}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-08-01-36-460/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.045},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-19-08-01-36-460\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-08-01-36-460/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.045\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.045\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.045\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\n",
      "2020-01-19 08:18:14 Uploading - Uploading generated training model\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:06:48.300 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:06:48.313 algo-1:44 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:06:48.313 algo-1:44 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:06:48.313 algo-1:44 INFO hook.py:325] Monitoring the collections: losses, scalars\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.637316 #011Validation Loss: 0.739167\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.739167).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.577723 #011Validation Loss: 0.793170\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.572032 #011Validation Loss: 0.810761\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.569790 #011Validation Loss: 0.823527\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.569966 #011Validation Loss: 0.823605\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.569683 #011Validation Loss: 0.826541\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.568673 #011Validation Loss: 0.825850\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.569239 #011Validation Loss: 0.825718\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.568359 #011Validation Loss: 0.826311\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.567640 #011Validation Loss: 0.820888\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.565406 #011Validation Loss: 0.819053\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.553878 #011Validation Loss: 0.797824\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.467700 #011Validation Loss: 0.657135\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.739167 --> 0.657135).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.265465 #011Validation Loss: 0.649438\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.657135 --> 0.649438).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.156855 #011Validation Loss: 0.837287\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.128676 #011Validation Loss: 0.946464\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.125113 #011Validation Loss: 0.574887\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.649438 --> 0.574887).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.110058 #011Validation Loss: 0.545919\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.574887 --> 0.545919).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.098661 #011Validation Loss: 0.879289\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.095752 #011Validation Loss: 0.288467\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.545919 --> 0.288467).  Saving model ...\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 0.3678636565804482\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 370\u001b[0m\n",
      "\u001b[34mFalse Positives: 73\u001b[0m\n",
      "\u001b[34mTrue Negatives: 161\u001b[0m\n",
      "\u001b[34mFalse Negatives: 20\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.8509615384615384\u001b[0m\n",
      "\u001b[34mRecall: 0.9487179487179487\u001b[0m\n",
      "\u001b[34mPrecision: 0.835214446952596\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.8183760683760684\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:18:11.897 algo-1:44 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-19 08:18:12,232 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-19 08:21:37 Completed - Training job completed\n",
      "Training seconds: 1058\n",
      "Billable seconds: 1058\n"
     ]
    }
   ],
   "source": [
    "my_estimator4.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.045<br>\n",
    "\n",
    "True Positives: 370<br>\n",
    "False Positives: 73<br>\n",
    "True Negatives: 161<br>\n",
    "False Negatives: 20<br>\n",
    "\n",
    "AUC Score: 0.8183760683760684 (Better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_estimator5 = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='cnn_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.04})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 08:25:49 Starting - Starting the training job...\n",
      "2020-01-19 08:25:51 Starting - Launching requested ML instances...\n",
      "2020-01-19 08:26:46 Starting - Preparing the instances for training............\n",
      "2020-01-19 08:28:40 Downloading - Downloading input data......\n",
      "2020-01-19 08:29:35 Training - Downloading the training image......\n",
      "2020-01-19 08:30:40 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-19 08:30:41,908 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-19 08:30:41,938 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-19 08:30:41,939 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-19 08:30:42,226 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-19 08:30:42,226 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-19 08:30:42,226 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-19 08:30:42,226 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpajfwxrgg/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=11732 sha256=0126d3fbb55e64fd5f3d736837f09e11b79146469fad4afc6c321e4186041fc9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k4g7a7s8/wheels/b8/9a/27/4bda608133c864f6131aa880837e68948070e3ecfa91d09327\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-19 08:30:44,533 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.04\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-19-08-25-49-128\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-08-25-49-128/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.04}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-08-25-49-128/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.04},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-19-08-25-49-128\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-08-25-49-128/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.04\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.04\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.04\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:30:53.168 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:30:53.181 algo-1:44 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:30:53.181 algo-1:44 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:30:53.181 algo-1:44 INFO hook.py:325] Monitoring the collections: losses, scalars\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.625023 #011Validation Loss: 0.739849\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.739849).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.580432 #011Validation Loss: 0.783637\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.572462 #011Validation Loss: 0.806165\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.570068 #011Validation Loss: 0.819559\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.569634 #011Validation Loss: 0.823035\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.569780 #011Validation Loss: 0.825177\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.569441 #011Validation Loss: 0.826162\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.568508 #011Validation Loss: 0.827961\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.568632 #011Validation Loss: 0.824833\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.568339 #011Validation Loss: 0.823345\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.565007 #011Validation Loss: 0.820117\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.545482 #011Validation Loss: 0.762747\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.423623 #011Validation Loss: 0.911686\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.249818 #011Validation Loss: 0.460276\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.739849 --> 0.460276).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.181140 #011Validation Loss: 0.698733\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.155973 #011Validation Loss: 0.979590\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.136300 #011Validation Loss: 1.318895\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.121521 #011Validation Loss: 0.296328\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.460276 --> 0.296328).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.105470 #011Validation Loss: 0.325531\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.106137 #011Validation Loss: 0.566355\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 0.6435696540400386\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 385\u001b[0m\n",
      "\u001b[34mFalse Positives: 145\u001b[0m\n",
      "\u001b[34mTrue Negatives: 89\u001b[0m\n",
      "\u001b[34mFalse Negatives: 5\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.7596153846153846\u001b[0m\n",
      "\u001b[34mRecall: 0.9871794871794872\u001b[0m\n",
      "\u001b[34mPrecision: 0.7264150943396226\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.6837606837606838\u001b[0m\n",
      "\u001b[34m[2020-01-19 08:42:08.233 algo-1:44 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-19 08:42:08,633 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-19 08:42:12 Uploading - Uploading generated training model\n",
      "2020-01-19 08:45:56 Completed - Training job completed\n",
      "Training seconds: 1036\n",
      "Billable seconds: 1036\n"
     ]
    }
   ],
   "source": [
    "my_estimator5.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.04<br>\n",
    "\n",
    "True Positives: 385<br>\n",
    "False Positives: 145<br>\n",
    "True Negatives: 89<br>\n",
    "False Negatives: 5<br>\n",
    "\n",
    "AUC Score: 0.6837606837606838 (Worse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing best model\n",
    "\n",
    "The fourth estimator of my own CNN with a learning rate of 0.045. It had the highest AUC Score of 0.8183760683760684.<br>\n",
    "The name of the training job is 'pytorch-training-2020-01-19-08-01-36-460'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-16 model\n",
    "Read more <a href=https://arxiv.org/pdf/1409.1556.pdf>here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_estimator = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='vgg_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 23:48:34 Starting - Preparing the instances for training\n",
      "2020-01-19 23:48:34 Downloading - Downloading input data\n",
      "2020-01-19 23:48:34 Training - Training image download completed. Training in progress.\n",
      "2020-01-19 23:48:34 Uploading - Uploading generated training model\n",
      "2020-01-19 23:48:34 Completed - Training job completed\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-19 22:57:43,371 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-19 22:57:43,395 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-19 22:57:46,423 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-19 22:57:46,727 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-19 22:57:46,727 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-19 22:57:46,727 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-19 22:57:46,728 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpyarrt7yw/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=10042 sha256=37dcd38be09ea1c89fbf1dc09a420a50e94d61a3bbdad01bd74968a169ba3f23\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o132_i7d/wheels/d9/ab/7d/716a34bce7169217f43a147b46708250e532eee3b744bb4366\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-19 22:57:49,100 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-19-22-52-35-248\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-22-52-35-248/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-22-52-35-248/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-19-22-52-35-248\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-19-22-52-35-248/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mDownloading the ResNeXt-101 32x8d model\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34mReplacing the model's Fully Connected Layer\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 22:57:56.943 algo-1:43 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-19 22:57:56.956 algo-1:43 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-19 22:57:56.956 algo-1:43 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-19 22:57:56.957 algo-1:43 INFO hook.py:325] Monitoring the collections: losses, scalars\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.585369 #011Validation Loss: 0.762948\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.762948).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.553986 #011Validation Loss: 0.817707\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.557376 #011Validation Loss: 0.834679\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.564604 #011Validation Loss: 0.840264\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.570243 #011Validation Loss: 0.823628\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.569684 #011Validation Loss: 0.827697\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.566004 #011Validation Loss: 0.816389\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.518722 #011Validation Loss: 0.921310\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.295078 #011Validation Loss: 1.114772\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.167733 #011Validation Loss: 0.376827\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.762948 --> 0.376827).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.124733 #011Validation Loss: 0.352503\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.376827 --> 0.352503).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.096745 #011Validation Loss: 0.547371\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.084508 #011Validation Loss: 0.276679\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.352503 --> 0.276679).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.070086 #011Validation Loss: 0.199476\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.276679 --> 0.199476).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.060890 #011Validation Loss: 0.648472\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.057745 #011Validation Loss: 0.554267\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.049173 #011Validation Loss: 0.408409\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.046301 #011Validation Loss: 0.067127\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.199476 --> 0.067127).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.085645 #011Validation Loss: 0.349111\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.039209 #011Validation Loss: 0.068758\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 1.2314107822225195\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 389\u001b[0m\n",
      "\u001b[34mFalse Positives: 146\u001b[0m\n",
      "\u001b[34mTrue Negatives: 88\u001b[0m\n",
      "\u001b[34mFalse Negatives: 1\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.7644230769230769\u001b[0m\n",
      "\u001b[34mRecall: 0.9974358974358974\u001b[0m\n",
      "\u001b[34mPrecision: 0.7271028037383177\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.6867521367521368\u001b[0m\n",
      "\u001b[34m[2020-01-19 23:47:10.217 algo-1:43 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-19 23:47:10,623 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 3172\n",
      "Billable seconds: 3172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.pytorch.estimator.PyTorch at 0x7efdf11e2da0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_estimator.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First VGG-16 Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.1<br>\n",
    "\n",
    "True Positives: 389<br>\n",
    "False Positives: 146<br>\n",
    "True Negatives: 88<br>\n",
    "False Negatives: 1<br>\n",
    "\n",
    "AUC Score: 0.6867521367521368 (Not good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_estimator2 = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='vgg_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-20 23:41:50 Starting - Starting the training job...\n",
      "2020-01-20 23:41:52 Starting - Launching requested ML instances...\n",
      "2020-01-20 23:42:49 Starting - Preparing the instances for training............\n",
      "2020-01-20 23:44:47 Downloading - Downloading input data......\n",
      "2020-01-20 23:45:40 Training - Downloading the training image......\n",
      "2020-01-20 23:46:45 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-20 23:46:46,239 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-20 23:46:46,264 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-20 23:46:46,265 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-20 23:46:46,530 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-20 23:46:46,531 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-20 23:46:46,531 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-20 23:46:46,531 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpvy7hyvsp/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=15710 sha256=f59282531bfc8acfce3f7b70bdbbad5fc28b262ade37b1cf9e66769b4b4995ca\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vp8jrt1p/wheels/f8/3f/61/80115ba8bf7e3e22ddc3a4b2f56f7d4987c8647f4dd9d2201f\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-20 23:46:48,769 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-20-23-41-49-889\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-20-23-41-49-889/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.05}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-20-23-41-49-889/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-20-23-41-49-889\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-20-23-41-49-889/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.05\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.05\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.05\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mDownloading the ResNeXt-101 32x8d model\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34mReplacing the model's Fully Connected Layer\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-20 23:46:56.217 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-21 00:34:20 Uploading - Uploading generated training model\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-20 23:46:56.231 algo-1:44 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-20 23:46:56.231 algo-1:44 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-20 23:46:56.232 algo-1:44 INFO hook.py:325] Monitoring the collections: scalars, losses\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.596083 #011Validation Loss: 0.825511\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.825511).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.562854 #011Validation Loss: 0.745037\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.825511 --> 0.745037).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.539856 #011Validation Loss: 0.738819\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.745037 --> 0.738819).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.320827 #011Validation Loss: 0.415765\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.738819 --> 0.415765).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.186295 #011Validation Loss: 0.799743\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.150813 #011Validation Loss: 1.007093\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.123687 #011Validation Loss: 1.247123\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.116713 #011Validation Loss: 0.491831\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.099970 #011Validation Loss: 0.277745\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.415765 --> 0.277745).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.083498 #011Validation Loss: 1.133675\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.094665 #011Validation Loss: 0.327776\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.070494 #011Validation Loss: 0.396194\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.070141 #011Validation Loss: 0.716107\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.057996 #011Validation Loss: 0.618016\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.047080 #011Validation Loss: 0.362875\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.077400 #011Validation Loss: 0.186884\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.277745 --> 0.186884).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.042027 #011Validation Loss: 0.246728\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.037458 #011Validation Loss: 0.083680\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.186884 --> 0.083680).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.285692 #011Validation Loss: 0.652996\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.068828 #011Validation Loss: 0.238943\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 1.0093304812631687\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 389\u001b[0m\n",
      "\u001b[34mFalse Positives: 128\u001b[0m\n",
      "\u001b[34mTrue Negatives: 106\u001b[0m\n",
      "\u001b[34mFalse Negatives: 1\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.7932692307692307\u001b[0m\n",
      "\u001b[34mRecall: 0.9974358974358974\u001b[0m\n",
      "\u001b[34mPrecision: 0.7524177949709865\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.7252136752136752\u001b[0m\n",
      "\u001b[34m[2020-01-21 00:34:19.849 algo-1:44 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-21 00:34:20,214 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-21 00:34:48 Completed - Training job completed\n",
      "Training seconds: 3001\n",
      "Billable seconds: 3001\n"
     ]
    }
   ],
   "source": [
    "vgg_estimator2.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second VGG-16 Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.05<br>\n",
    "\n",
    "True Positives: 389<br>\n",
    "False Positives: 128<br>\n",
    "True Negatives: 106<br>\n",
    "False Negatives: 1<br>\n",
    "\n",
    "AUC Score: 0.7252136752136752 (Better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_estimator3 = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='vgg_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-21 00:37:00 Starting - Starting the training job...\n",
      "2020-01-21 00:37:01 Starting - Launching requested ML instances...\n",
      "2020-01-21 00:37:58 Starting - Preparing the instances for training............\n",
      "2020-01-21 00:39:33 Downloading - Downloading input data.........\n",
      "2020-01-21 00:41:03 Training - Downloading the training image.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-21 00:42:09,368 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-21 00:42:09,396 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-21 00:42:12,432 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-21 00:42:12,824 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-21 00:42:12,824 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-21 00:42:12,824 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-21 00:42:12,825 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmp4mdw2t18/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=15711 sha256=6c26d0074b376af60d3f550aa6cbee198c20b5f9a6a5680c1abed8d3817230b3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cazggdob/wheels/2c/24/e4/c8cddfe7af41041766e05d2f03309f61278d325ea33cbb4379\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-21 00:42:15,647 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-21-00-36-59-799\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-00-36-59-799/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-00-36-59-799/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-21-00-36-59-799\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-00-36-59-799/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.01\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\n",
      "2020-01-21 00:42:07 Training - Training image download completed. Training in progress.\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mDownloading the ResNeXt-101 32x8d model\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34mReplacing the model's Fully Connected Layer\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-21 00:42:24.599 algo-1:44 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-21 01:29:01 Uploading - Uploading generated training model\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-21 00:42:24.612 algo-1:44 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-21 00:42:24.612 algo-1:44 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-21 00:42:24.613 algo-1:44 INFO hook.py:325] Monitoring the collections: losses, scalars\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.661753 #011Validation Loss: 0.700790\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.700790).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.628231 #011Validation Loss: 0.714947\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.605406 #011Validation Loss: 0.741168\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.584318 #011Validation Loss: 0.824917\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.575314 #011Validation Loss: 0.828295\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.555813 #011Validation Loss: 0.938035\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.470855 #011Validation Loss: 0.758818\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.353843 #011Validation Loss: 1.528849\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.266332 #011Validation Loss: 0.987354\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.203820 #011Validation Loss: 0.989915\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.172180 #011Validation Loss: 0.668759\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.700790 --> 0.668759).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.157121 #011Validation Loss: 1.385386\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.148372 #011Validation Loss: 0.600783\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.668759 --> 0.600783).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.130734 #011Validation Loss: 0.507521\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.600783 --> 0.507521).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.127299 #011Validation Loss: 0.239025\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.507521 --> 0.239025).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.120552 #011Validation Loss: 0.411380\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.106696 #011Validation Loss: 0.399924\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.107341 #011Validation Loss: 0.310234\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.092994 #011Validation Loss: 0.604650\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.094744 #011Validation Loss: 0.409370\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 1.0316415645647794\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 386\u001b[0m\n",
      "\u001b[34mFalse Positives: 147\u001b[0m\n",
      "\u001b[34mTrue Negatives: 87\u001b[0m\n",
      "\u001b[34mFalse Negatives: 4\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.7580128205128205\u001b[0m\n",
      "\u001b[34mRecall: 0.9897435897435898\u001b[0m\n",
      "\u001b[34mPrecision: 0.724202626641651\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.6807692307692308\u001b[0m\n",
      "\u001b[34m[2020-01-21 01:28:56.854 algo-1:44 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-21 01:28:57,201 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-21 01:29:28 Completed - Training job completed\n",
      "Training seconds: 2995\n",
      "Billable seconds: 2995\n"
     ]
    }
   ],
   "source": [
    "vgg_estimator3.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third VGG-16 Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.01<br>\n",
    "\n",
    "True Positives: 386<br>\n",
    "False Positives: 147<br>\n",
    "True Negatives: 87<br>\n",
    "False Negatives: 4<br>\n",
    "\n",
    "AUC Score: 0.6807692307692308 (Not so good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_estimator4 = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='vgg_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.8xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.065})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-21 01:34:52 Starting - Starting the training job...\n",
      "2020-01-21 01:34:53 Starting - Launching requested ML instances.........\n",
      "2020-01-21 01:36:49 Starting - Preparing the instances for training.........\n",
      "2020-01-21 01:38:23 Downloading - Downloading input data......\n",
      "2020-01-21 01:39:23 Training - Downloading the training image......\n",
      "2020-01-21 01:40:11 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-21 01:40:12,938 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-21 01:40:13,020 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-21 01:40:16,045 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-21 01:40:16,334 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-21 01:40:16,335 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-21 01:40:16,335 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-21 01:40:16,335 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpw_wyl04z/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\n",
      "  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=15710 sha256=3f9894b1cb27ab3ae4ce1c354dcd6e45fcd777b86549cd99596ff7977d52e42d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-m961hct1/wheels/1b/42/fb/0e401a100c8ee50bbb88c6080a7950d5c547ff57aea1b965c3\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-21 01:40:18,830 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.065\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-21-01-34-51-820\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-01-34-51-820/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.065}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-01-34-51-820/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.065},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-21-01-34-51-820\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-01-34-51-820/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.065\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.065\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.065\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mDownloading the ResNeXt-101 32x8d model\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34mReplacing the model's Fully Connected Layer\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-21 01:40:26.909 algo-1:72 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-21 02:27:18 Uploading - Uploading generated training model\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-21 01:40:26.921 algo-1:72 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-21 01:40:26.921 algo-1:72 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-21 01:40:26.922 algo-1:72 INFO hook.py:325] Monitoring the collections: losses, scalars\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.619237 #011Validation Loss: 0.854506\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.854506).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.571644 #011Validation Loss: 0.763905\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.854506 --> 0.763905).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.570581 #011Validation Loss: 0.795991\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.540818 #011Validation Loss: 0.735135\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.763905 --> 0.735135).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.556648 #011Validation Loss: 0.843641\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.530199 #011Validation Loss: 0.862279\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.333708 #011Validation Loss: 0.912662\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.164573 #011Validation Loss: 0.348110\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.735135 --> 0.348110).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.133950 #011Validation Loss: 1.321875\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.104815 #011Validation Loss: 0.272605\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.348110 --> 0.272605).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.104668 #011Validation Loss: 0.737323\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.082130 #011Validation Loss: 0.373051\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.086243 #011Validation Loss: 0.331371\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.064050 #011Validation Loss: 0.236157\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.272605 --> 0.236157).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.054114 #011Validation Loss: 0.170221\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.236157 --> 0.170221).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.049297 #011Validation Loss: 0.768344\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.033793 #011Validation Loss: 0.042445\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.170221 --> 0.042445).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.041513 #011Validation Loss: 0.523378\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.024547 #011Validation Loss: 0.619322\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.034266 #011Validation Loss: 0.031206\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.042445 --> 0.031206).  Saving model ...\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 1.5744141718011633\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 390\u001b[0m\n",
      "\u001b[34mFalse Positives: 139\u001b[0m\n",
      "\u001b[34mTrue Negatives: 95\u001b[0m\n",
      "\u001b[34mFalse Negatives: 0\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.7772435897435898\u001b[0m\n",
      "\u001b[34mRecall: 1.0\u001b[0m\n",
      "\u001b[34mPrecision: 0.7372400756143668\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.7029914529914529\u001b[0m\n",
      "\u001b[34m[2020-01-21 02:27:16.390 algo-1:72 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-21 02:27:16,918 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-21 02:27:46 Completed - Training job completed\n",
      "Training seconds: 2963\n",
      "Billable seconds: 2963\n"
     ]
    }
   ],
   "source": [
    "vgg_estimator4.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth VGG-16 Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.065<br>\n",
    "\n",
    "True Positives: 390<br>\n",
    "False Positives: 139<br>\n",
    "True Negatives: 95<br>\n",
    "False Negatives: 0<br>\n",
    "\n",
    "AUC Score: 0.7029914529914529 (Not so good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_estimator5 = PyTorch(entry_point='TrainandTest.py',\n",
    "                    source_dir='vgg_source', \n",
    "                    role=role, \n",
    "                    sagemaker_session=sagemaker_session, \n",
    "                    train_instance_count=1, \n",
    "                    train_instance_type='ml.p2.8xlarge', \n",
    "                    framework_version='1.3.1',\n",
    "                    hyperparameters={'epochs':20, 'learning_rate':0.045})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-21 03:54:55 Starting - Starting the training job...\n",
      "2020-01-21 03:54:57 Starting - Launching requested ML instances......\n",
      "2020-01-21 03:56:24 Starting - Preparing the instances for training.........\n",
      "2020-01-21 03:57:52 Downloading - Downloading input data......\n",
      "2020-01-21 03:58:36 Training - Downloading the training image......\n",
      "2020-01-21 03:59:42 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-21 03:59:43,597 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-21 03:59:43,679 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-21 03:59:45,088 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-21 03:59:45,352 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-21 03:59:45,353 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-21 03:59:45,353 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-21 03:59:45,353 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmplddbal5n/module_dir\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: default-user-module-name\n",
      "  Building wheel for default-user-module-name (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for default-user-module-name (setup.py): finished with status 'done'\n",
      "  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=15710 sha256=2475ab5b126857d4ce53d2372e1bef91c8b95b52dcba8335bfab5d470f8b4a59\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vrnt61ir/wheels/2d/01/e2/ee9eb1ca27c7e139dec8933df69583a6153c35ad75e2db9024\u001b[0m\n",
      "\u001b[34mSuccessfully built default-user-module-name\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-21 03:59:48,193 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 20,\n",
      "        \"learning_rate\": 0.045\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-21-03-54-55-622\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-03-54-55-622/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TrainandTest\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TrainandTest.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":20,\"learning_rate\":0.045}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TrainandTest.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TrainandTest\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-03-54-55-622/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":20,\"learning_rate\":0.045},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-21-03-54-55-622\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-991170486756/pytorch-training-2020-01-21-03-54-55-622/source/sourcedir.tar.gz\",\"module_name\":\"TrainandTest\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TrainandTest.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"20\",\"--learning_rate\",\"0.045\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.045\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python TrainandTest.py --epochs 20 --learning_rate 0.045\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mDownloading the ResNeXt-101 32x8d model\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34mReplacing the model's Fully Connected Layer\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34mStarting to train...\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-21 03:59:56.353 algo-1:72 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-21 04:46:50 Uploading - Uploading generated training model\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\u001b[0m\n",
      "\u001b[34m[2020-01-21 03:59:56.366 algo-1:72 INFO hook.py:151] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\u001b[0m\n",
      "\u001b[34m[2020-01-21 03:59:56.366 algo-1:72 INFO hook.py:196] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-01-21 03:59:56.367 algo-1:72 INFO hook.py:325] Monitoring the collections: scalars, losses\u001b[0m\n",
      "\u001b[34mEpoch: 1 #011Training Loss: 0.612536 #011Validation Loss: 0.880839\u001b[0m\n",
      "\u001b[34mValidation loss decreased (inf --> 0.880839).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 2 #011Training Loss: 0.545455 #011Validation Loss: 0.926497\u001b[0m\n",
      "\u001b[34mEpoch: 3 #011Training Loss: 0.577259 #011Validation Loss: 0.785011\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.880839 --> 0.785011).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 4 #011Training Loss: 0.568953 #011Validation Loss: 0.801372\u001b[0m\n",
      "\u001b[34mEpoch: 5 #011Training Loss: 0.512604 #011Validation Loss: 0.796199\u001b[0m\n",
      "\u001b[34mEpoch: 6 #011Training Loss: 0.336767 #011Validation Loss: 0.750018\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.785011 --> 0.750018).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 7 #011Training Loss: 0.180164 #011Validation Loss: 0.774275\u001b[0m\n",
      "\u001b[34mEpoch: 8 #011Training Loss: 0.151829 #011Validation Loss: 0.644396\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.750018 --> 0.644396).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 9 #011Training Loss: 0.126056 #011Validation Loss: 0.662772\u001b[0m\n",
      "\u001b[34mEpoch: 10 #011Training Loss: 0.107310 #011Validation Loss: 2.392398\u001b[0m\n",
      "\u001b[34mEpoch: 11 #011Training Loss: 0.098123 #011Validation Loss: 0.223294\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.644396 --> 0.223294).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 12 #011Training Loss: 0.086729 #011Validation Loss: 0.202371\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.223294 --> 0.202371).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 13 #011Training Loss: 0.071174 #011Validation Loss: 0.181991\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.202371 --> 0.181991).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 14 #011Training Loss: 0.067834 #011Validation Loss: 0.100271\u001b[0m\n",
      "\u001b[34mValidation loss decreased (0.181991 --> 0.100271).  Saving model ...\u001b[0m\n",
      "\u001b[34mEpoch: 15 #011Training Loss: 0.054932 #011Validation Loss: 0.459029\u001b[0m\n",
      "\u001b[34mEpoch: 16 #011Training Loss: 0.054247 #011Validation Loss: 0.124746\u001b[0m\n",
      "\u001b[34mEpoch: 17 #011Training Loss: 0.150849 #011Validation Loss: 0.273547\u001b[0m\n",
      "\u001b[34mEpoch: 18 #011Training Loss: 0.064966 #011Validation Loss: 0.182602\u001b[0m\n",
      "\u001b[34mEpoch: 19 #011Training Loss: 0.055898 #011Validation Loss: 0.535572\u001b[0m\n",
      "\u001b[34mEpoch: 20 #011Training Loss: 0.044986 #011Validation Loss: 0.125430\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNow After Training, we can now test the images to calculate the Accuracy and AUC Score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTotal Test Loss: 1.2887869731986938\n",
      "\u001b[0m\n",
      "\u001b[34mTrue Positives: 390\u001b[0m\n",
      "\u001b[34mFalse Positives: 151\u001b[0m\n",
      "\u001b[34mTrue Negatives: 83\u001b[0m\n",
      "\u001b[34mFalse Negatives: 0\n",
      "\u001b[0m\n",
      "\u001b[34mAccuracy: 0.7580128205128205\u001b[0m\n",
      "\u001b[34mRecall: 1.0\u001b[0m\n",
      "\u001b[34mPrecision: 0.7208872458410351\u001b[0m\n",
      "\u001b[34mAUC SCORE: 0.6773504273504274\u001b[0m\n",
      "\u001b[34m[2020-01-21 04:46:46.707 algo-1:72 INFO utils.py:27] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-01-21 04:46:47,213 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-21 04:47:17 Completed - Training job completed\n",
      "Training seconds: 2965\n",
      "Billable seconds: 2965\n"
     ]
    }
   ],
   "source": [
    "vgg_estimator5.fit({'train':train_location, 'validation':val_location, 'test':test_location}, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth VGG-16 Model <br>\n",
    "Epochs: 20<br>\n",
    "Learning Rate: 0.045<br>\n",
    "\n",
    "True Positives: 390<br>\n",
    "False Positives: 151<br>\n",
    "True Negatives: 83<br>\n",
    "False Negatives: 0<br>\n",
    "\n",
    "AUC Score: 0.6773504273504274 (Not good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best VGG-16 Model\n",
    "The best vgg-16 is the second model with a learning rate of 0.05. It had the highest AUC Score of 0.7252136752136752.<br>\n",
    "The name of the training job is: 'pytorch-training-2020-01-20-23-41-49-889'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up Next: Comparing the Best Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
